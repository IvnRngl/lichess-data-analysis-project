{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lichess Data Analysis Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, Lichess makes it's database available [here](https://database.lichess.org/). I downloaded the standard games from November 2023 with .pgn.zst extension, which I then decompressed using PeaZip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a MySQL table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE games_metadata(\n",
    "    id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    gameType VARCHAR(255),\n",
    "    white VARCHAR(255),\n",
    "    black VARCHAR(255),\n",
    "    result VARCHAR(255),\n",
    "    utcDate DATE,\n",
    "    utcTime TIME,\n",
    "    whiteElo INT,\n",
    "    blackElo INT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I used the following python code to send the relevant metadata (name of players, their rating, the result, time control and datetime info) of each game into a MySQL table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from chess.pgn import read_game\n",
    "\n",
    "path_to_pgn_data = \"database/lichess_db_standard_rated_2023-11.pgn\"\n",
    "insert_into_database_sql_string = '''\n",
    "        INSERT INTO games_metadata (gameType, white, black, result, utcDate, utcTime, whiteElo, blackElo) \n",
    "        VALUES (%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "        '''\n",
    "connect_params = {\n",
    "    \"host\":\"\",\n",
    "    \"user\":\"\",\n",
    "    \"password\":\"\",\n",
    "    \"database\":\"\"} # This dict should contain the relevant info for the mysql connector to reach the database\n",
    "\n",
    "def connect_to_db_and_upload_list_of_rows(list_of_tuples: list[tuple]):\n",
    "    db = mysql.connector.connect(**connect_params)\n",
    "\n",
    "    cursor = db.cursor()\n",
    "    cursor.executemany(\n",
    "        insert_into_database_sql_string, \n",
    "        list_of_tuples)\n",
    "    db.commit()\n",
    "    db.close()\n",
    "\n",
    "# So as not to exceed memory capaity, I'm inserting chunks of 10,000 rows. If done on multiple sessions you can use the empty_iterations \n",
    "def insert_into_database(data_path: str = path_to_pgn_data, chunksize: int = 10_000, iterations: int = 100, empty_iterations: int = 0):\n",
    "    with open(data_path) as file:\n",
    "        for _ in range(empty_iterations):\n",
    "            game = read_game(file)\n",
    "        for i in range(iterations):\n",
    "            list_of_rows = []\n",
    "            for _ in range(chunksize):\n",
    "                game = read_game(file)\n",
    "                data_tuple = (game.headers[\"Event\"].split(\" \")[1], \n",
    "                            game.headers[\"White\"],\n",
    "                            game.headers[\"Black\"], \n",
    "                            game.headers[\"Result\"],\n",
    "                            game.headers[\"UTCDate\"].replace(\".\", \"-\"),\n",
    "                            game.headers[\"UTCTime\"],\n",
    "                            game.headers[\"WhiteElo\"],\n",
    "                            game.headers[\"BlackElo\"])\n",
    "\n",
    "                list_of_rows.append(data_tuple)\n",
    "\n",
    "            connect_to_db_and_upload_list_of_rows(list_of_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially I wanted to have as big a dataset as possible, but due to certain bottlenecks I changed that to only the games in a single day (the previous code uploads games in order): November 1st."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the SQLTools extension in vscode and the following code I created csv's for every time control containing a column for all distinct players, a column for the aumount of white games, a column for black games, and another for the total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT\n",
    "    w.player AS player,\n",
    "    w.num_games_as_white AS white_games,\n",
    "    b.num_games_as_black AS black_games,\n",
    "    w.num_games_as_white + b.num_games_as_black AS total\n",
    "FROM\n",
    "    (SELECT\n",
    "        DISTINCT white AS player,\n",
    "        COUNT(*) AS num_games_as_white\n",
    "    FROM\n",
    "        games_metadata\n",
    "    WHERE\n",
    "        utcDate = \"2023-11-01\" AND gameType = \"Correspondence\" -- The second condition can be altered to focus on a given time control or removed to look at all time controls simultaneously\n",
    "    GROUP BY\n",
    "        white\n",
    "    ORDER BY\n",
    "        num_games_as_white DESC) AS w\n",
    "    INNER JOIN\n",
    "    (SELECT\n",
    "        DISTINCT black AS player,\n",
    "        COUNT(*) AS num_games_as_black\n",
    "    FROM\n",
    "        games_metadata\n",
    "    WHERE\n",
    "        utcDate = \"2023-11-01\" AND gameType = \"Correspondence\" -- Same as the previous comment\n",
    "    GROUP BY\n",
    "        black\n",
    "    ORDER BY\n",
    "        num_games_as_black DESC) AS b\n",
    "    ON w.player = b.player\n",
    "ORDER BY\n",
    "    total DESC,\n",
    "    player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future reference I named the csv's \"MostActivePlayersAll.csv\", \"MostActivePlayersClassical.csv\", etc. This will be important for the Pareto bar chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also copied the table, first into a csv, and then into a .pickle with the correct data types, called \"NovemberFirst\" for easy use with pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the pie graph's data we run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, Series, read_pickle, read_csv\n",
    "\n",
    "df: DataFrame = read_pickle(\"database/NovemberFirst.pickle\")\n",
    "\n",
    "total_games = len(df.index)\n",
    "total_games_correspondence = len(df[df[\"gameType\"] == \"Correspondence\"].index)\n",
    "total_games_classical = len(df[df[\"gameType\"] == \"Classical\"].index)\n",
    "total_games_rapid = len(df[df[\"gameType\"] == \"Rapid\"].index)\n",
    "total_games_blitz = len(df[df[\"gameType\"] == \"Blitz\"].index)\n",
    "total_games_bullet = len(df[df[\"gameType\"] == \"Bullet\"].index)\n",
    "total_games_ultrabullet = len(df[df[\"gameType\"] == \"UltraBullet\"].index)\n",
    "\n",
    "print(f\"There where a total of {total_games}\\n\")\n",
    "print(f\"{total_games_correspondence} correspondence games, equivalent to {round(total_games_correspondence*100/total_games, 2)}%\")\n",
    "print(f\"{total_games_classical} classical games, equivalent to {round(total_games_classical*100/total_games, 2)}%\")\n",
    "print(f\"{total_games_rapid} rapid games, equivalent to {round(total_games_rapid*100/total_games, 2)}%\")\n",
    "print(f\"{total_games_blitz} blitz games, equivalent to {round(total_games_blitz*100/total_games, 2)}%\")\n",
    "print(f\"{total_games_bullet} bullet games, equivalent to {round(total_games_bullet*100/total_games, 2)}%\")\n",
    "print(f\"{total_games_ultrabullet} ultra bullet games, equivalent to {round(total_games_ultrabullet*100/total_games, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Pareto bar chart first we need to know how many distinct players there where across all time controls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: DataFrame = read_pickle(\"database/NovemberFirst.pickle\")\n",
    "\n",
    "df = df[df[\"gameType\"] == \"Blitz\"] # This line can be altered for different time controls, or deleted to get the full picture\n",
    "players = []\n",
    "players.extend(list(df[\"white\"]))\n",
    "players.extend(list(df[\"black\"]))\n",
    "distinct_players = list(set(players))\n",
    "\n",
    "print(f\"There where {len(distinct_players)} distinct players\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the data fot the Pareto bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: DataFrame = read_pickle(\"database/NovemberFirst.pickle\")\n",
    "\n",
    "game_type = \"Blitz\" # This line and the next can be altered to focus on different time controls, or removed to get the full picture\n",
    "df = df[df[\"gameType\"] == game_type]\n",
    "players = list(read_csv(\"database/MostActivePlayersBlitz.csv\")[\"player\"]) # this line should be altered like the previous one\n",
    "total_players = 377134 # Here we write the number of total distinct players for the corresponding game type\n",
    "total_games = 1481528 # Here we write the number of total games for the corresponding game type\n",
    "for i in [5, 10, 20, 33, 50]:\n",
    "    number = len(df[(df[\"white\"].isin(players[:int(total_players*(i/100))])) | (df[\"black\"].isin(players[:int(total_players*(i/100))]))])\n",
    "    print(f\"The {i}% most active {game_type.lower()} players are involved in {number} games, which is {round(number*100/total_games, 2)}% of the total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, for the distribution chart we run this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: DataFrame = read_pickle(\"database/NovemberFirst.pickle\")\n",
    "\n",
    "df[\"avgRating\"] = (df[\"whiteElo\"] + df[\"blackElo\"]) / 2\n",
    "df[\"avgRatingByIncrements\"] = df[\"avgRating\"] - (df[\"avgRating\"] % 50)\n",
    "df[\"avgRatingByIncrements\"] = df[\"avgRatingByIncrements\"].astype(int)\n",
    "\n",
    "n_by_avgRating: Series = df.groupby(\"avgRatingByIncrements\")[\"white\"].count()\n",
    "print(n_by_avgRating)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
